{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIdI4x4_2RMQ"
      },
      "source": [
        "## <h1><center>Assignment 1: Classification With Convolutional Neural Networks</center></h1>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<center><img src=\"https://www.cs.cornell.edu/courses/cs4782/2025sp/slides/traffic_sign.jpeg\"></center>\n",
        "\n",
        "\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**GOAL:** In this assignment you will be implementing different CNNs for traffic sign detection. You will also implement a few optimization techniques along the way such as dropout and batch normalization.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "**WHAT YOU'LL SUBMIT:** Your submission to Gradescope includes:\n",
        "\n",
        "1.   Files `submission.py` and `resnet_preds.csv` uploaded to [***Coding Assignment 1***](https://www.gradescope.com/courses/963234/assignments/5744368).\n",
        "2.   A PDF containing responses to questions in the notebook, uploaded to [***Coding Assignment 1 Written Responses***](https://www.gradescope.com/courses/963234/assignments/5744437).\n",
        "\n",
        "*More on how you are expected to access, modify and save these files as you follow along the instructions in the notebook.*\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "**DO's:**\n",
        "\n",
        "1.   **Running on GPU: Before you begin make sure to click on the runtime option and change your runtime type to the T4 GPU (this should make your training faster)**\n",
        "2.   You will need to write code in the `## TODO` sections of `submission.py`.\n",
        "3.   Remember to execute all code cells sequentially, not just those youâ€™ve edited, to ensure your code runs properly.\n",
        "4.   Please cite any external sources you use to complete this assignment in your written responses.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "**DONT's:**\n",
        "\n",
        "\n",
        "1.   DO NOT change the names of any provided functions, classes, or variables within the existing code cells, as this will interfere with grading.\n",
        "2.   DO NOT delete any provided code/imports.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "***NOTE:***\n",
        "    \n",
        "*You can resubmit your work as many times as necessary before the submission deadline. If you experience difficulty or have questions about this exercise, use the Ed discussion board to engage with your peers or seek assistance from the instructor.*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFGP8Lyl2Jpm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "from matplotlib import cm\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgX-tzXMn_XW"
      },
      "source": [
        "PyTorch is one of the most popular deep learning frameworks, and we will use PyTorch for all of the assignments this semester.\n",
        "If this is your first time using PyTorch, [here](https://pytorch.org/tutorials/beginner/basics/intro.html) are some basic tutorials to get you started.\n",
        "\n",
        "Please make sure you are familiar with writing vectorized code; avoid the usage of `for` loops as much as possible.\n",
        "Vectorized operations ensures that PyTorch is using the parallelism efficiently and also makes your codes more readable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THhardHgFHms"
      },
      "source": [
        "# Part 0: Setting up the Colab environment.\n",
        "In order to make sure the dataset and your implementation can be accessed by this notebook, we will need to mount the runtime environment to your Google drive and specify where these files are. Upload the a1_release folder to your Google Drive and run the cells below, following the TODO instructions.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dFjSQeFHftL"
      },
      "outputs": [],
      "source": [
        "# Mount your Google Drive to Colab; this allows the runtime environment to access your drive.\n",
        "# You should see the `gdrive` folder appear in your `Files` tab on the left (folder icon).\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSyiu4Pn8GUt"
      },
      "outputs": [],
      "source": [
        "# TODO: After mounting, find the DIRECTORY which contains `submission.py` and the .pkl files in the `Files` tab.\n",
        "# You can get the path to the directory by right clicking on the directory and pressing 'Copy path'.\n",
        "\n",
        "# !! Make sure you do NOT to include a '/' at the end of the path !!\n",
        "base_dir = \"/content/gdrive/MyDrive/<path-to-a1-release>\"\n",
        "sys.path.append(base_dir)\n",
        "\n",
        "# NOTE: Once you have pasted the path in, you should be able to (ctrl+click) on the path to to open\n",
        "# the Files tab and see `submission.py` in the explorer. You can then double click submission.py to open an IDE in Colab.\n",
        "# The (ctrl+click) to auto-navigate to `submission.py` will not work if there are spaces in the file path. \n",
        "# Navigate manually or save a1_release to a path with no white spaces.\n",
        "\n",
        "## END TODO\n",
        "\n",
        "# This makes sure the submission module is reloaded whenever you make edits.\n",
        "%load_ext autoreload\n",
        "%aimport submission\n",
        "%autoreload 1\n",
        "import submission\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qApyemQ55eFD"
      },
      "source": [
        "# Part 1: Load the Dataset (0 pts)\n",
        "We will be using a road sign detection dataset (https://www.kaggle.com/datasets/andrewmvd/road-sign-detection). It has four distinct classes \"Traffic Light\", \"Stop\", \"Speedlimit, and \"crosswalk\" and the objective is to classify each image in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO8deVuXXNpL"
      },
      "outputs": [],
      "source": [
        "classes = [\n",
        "    'trafficlight',\n",
        "    'stop',\n",
        "    'speedlimit',\n",
        "    'crosswalk'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd-DTb3M58ZR"
      },
      "source": [
        "This next cell creates a PickleDataset class for loading datasets from the .pkl files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKI6HJLkWmhB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class PickleDataset(Dataset):\n",
        "    def __init__(self, pkl_file, test_mode=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pkl_file (str): Path to the pickle file.\n",
        "            test_mode (bool): If True, the dataset will return only the image.\n",
        "                              If False, it returns (image, label).\n",
        "        \"\"\"\n",
        "        with open(pkl_file, 'rb') as f:\n",
        "            self.data = pickle.load(f)\n",
        "        self.test_mode = test_mode\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.data[idx]\n",
        "        if self.test_mode:\n",
        "            # Return only the image for the test set\n",
        "            return image\n",
        "        else:\n",
        "            return image, label\n",
        "\n",
        "\n",
        "def load_dataset(split, base_dir, test_mode=False):\n",
        "    \"\"\"\n",
        "    Loads the dataset for the given split.\n",
        "    For test mode, pass test_mode=True so that labels are not returned.\n",
        "    \"\"\"\n",
        "    pkl_file = os.path.join(base_dir, f\"{split}_data.pkl\")\n",
        "    try:\n",
        "        dataset = PickleDataset(pkl_file, test_mode=test_mode)\n",
        "        print(f\"Loaded {len(dataset)} samples from {pkl_file}\")\n",
        "        return dataset\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"The file {pkl_file} was not found. Please ensure it exists.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqw7v7lm6OQL"
      },
      "source": [
        "Run the cell below to create the training, test and validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUasuk24hhZy"
      },
      "outputs": [],
      "source": [
        "train_dataset = load_dataset(\"train\", base_dir)\n",
        "val_dataset = load_dataset(\"val\", base_dir)\n",
        "test_dataset = load_dataset(\"test\", base_dir, test_mode=True)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6Q6JkUPHHkK"
      },
      "source": [
        "Note that these datasets have had the following transforms already applied to them which will cause visualizations to appear a little unusual.\n",
        "\n",
        "```py\n",
        "data_mean = [0.4910, 0.4884, 0.5115]\n",
        "data_std  = [0.2489, 0.2475, 0.2343]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x[:3, :, :]),\n",
        "    transforms.Normalize(data_mean, data_std),\n",
        "])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hVWW01AFPvl"
      },
      "source": [
        "Run the cells below to visualize an image from the dataset and verify that the dataloader is working properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsgHAjv_65NP"
      },
      "outputs": [],
      "source": [
        "image, label = train_dataset[4]\n",
        "to_pil = transforms.ToPILImage()\n",
        "pil_image = to_pil(image)\n",
        "plt.imshow(pil_image)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqpmlEcU8jWL"
      },
      "outputs": [],
      "source": [
        "for batch_idx, (data, target) in enumerate(train_dataloader):\n",
        "    # Check the shape and type of the data\n",
        "    print(f\"Batch {batch_idx}:\")\n",
        "    print(f\"Data - Shape: {data.shape}, Type: {data.dtype}\")\n",
        "    print(f\"Target - Shape: {target.shape}, Type: {target.dtype}\")\n",
        "    if batch_idx == 2:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wet5Lz1Q1-ru"
      },
      "source": [
        "# Part 2: Training Loop (10 pts)\n",
        "Create a training loop for the model. The data_loader provides batches of images and their labels. For each batch, we need to:\n",
        "\n",
        "1. Zero out the gradients of the model\n",
        "2. Perform a forward pass through the model.\n",
        "3. Compute the loss using the specified criterion.\n",
        "4. Perform the backward pass.\n",
        "5. Update the model parameters using the optimizer.\n",
        "\n",
        "\n",
        "You will need to keep track of the train and validation losses at each epoch. You need to store them in the `train_loss_arr` and `val_loss_arr` lists. You should accumulate the training loss throughout the epoch. You need to call the provided `val()` function at the end of each epoch to compute the validation loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OFUz1YOWPYB"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCpTKH_25S9C"
      },
      "outputs": [],
      "source": [
        "#----------------------------------------#\n",
        "# TODO: Implement train in submission.py #\n",
        "#----------------------------------------#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fYixCVm4orc"
      },
      "source": [
        "# Part 3: Create a Convolutional Neural Network (10 pts)\n",
        "## Part 3.1\n",
        "We will begin by implementing a simple Convolutional Neural Network without Pooling or extra features.\n",
        "The base model architecture that you need to implement has the following components:\n",
        "- **conv1**: convolution layer with 4 output channels, kernel size of 3, stride of 2, padding of 1 (input is a color image)\n",
        "- **ReLU** nonlinearity\n",
        "- **conv2**: convolution layer with 16 output channels, kernel size of 3, stride of 2, padding of 1\n",
        "- **ReLU** nonlinearity\n",
        "- **conv3**: convolution layer with 32 output channels, kernel size of 3, stride of 2, padding of 1\n",
        "- **ReLU** nonlinearity\n",
        "- **fc1**:    fully connected layer with 1024 output features\n",
        "- **ReLU** nonlinearity\n",
        "- **fc2**:   fully connected layer with 4 output features (the number of classes)\n",
        "\n",
        "Hint: Make use of the functions here: https://pytorch.org/docs/stable/nn.html.\n",
        "\n",
        "**Note that for the relu you should use functional version of ReLU (i.e. F.relu) for the creation of the ConvNet. Also, please follow the names given above for the layer names. This also applies to the rest of the models you will create (ConvNetMaxPooling, ConvNetBN, and ConvNetDropout, ResidualBlock, and ResNet)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEr8A_weF2cb"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------#\n",
        "# TODO: Implement ConvNet in submission.py #\n",
        "#------------------------------------------#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY6HMlxZJQTX"
      },
      "source": [
        "Use the following test as a sanity check (it only checks the out shape). This test does not guarantee correctness of the full implementation. Feel free to add additional test cases!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNvmqR3NrS_I"
      },
      "outputs": [],
      "source": [
        "def testConvNet():\n",
        "  net = submission.ConvNet()\n",
        "  input_tensor = torch.randn(1, 3, 64, 64)\n",
        "  output = net(input_tensor)\n",
        "  assert(output.size() ==torch.Size([1, 4]))\n",
        "\n",
        "testConvNet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO6XaZfIcEbt"
      },
      "source": [
        "## Part 3.2\n",
        "Experiment with 3-5 learning rates and plot the performance curves for the different learning rates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6ZvSyIu_E6P"
      },
      "outputs": [],
      "source": [
        "train_loss_results = dict()\n",
        "val_loss_results = dict()\n",
        "\n",
        "for learning_rate in [\n",
        "    1e-2,\n",
        "    # TODO: Add at least two more learning rate settings\n",
        "]:\n",
        "  print('-'*20)\n",
        "  print(f\"learning_rate: {learning_rate}\")\n",
        "  model_conv = submission.ConvNet()\n",
        "  model_conv.to(device)\n",
        "  optimizer = optim.SGD(model_conv.parameters(), lr=learning_rate, momentum=0.9)\n",
        "  data_loader = train_dataloader\n",
        "  epochs = 20\n",
        "  convnet_train_loss, convnet_val_loss = submission.train(model_conv, data_loader, val_dataloader, criterion, optimizer, epochs, device)\n",
        "  train_loss_results[learning_rate] = convnet_train_loss\n",
        "  val_loss_results[learning_rate] = convnet_val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmYHQeWQdKwj"
      },
      "outputs": [],
      "source": [
        "# Plots the training loss and test accuracy curves for different learning rates here\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "for learning_rate, loss in train_loss_results.items():\n",
        "  axs[0].plot(loss, label=f\"lr={learning_rate}\")\n",
        "axs[0].set_xlabel(\"Epochs\")\n",
        "axs[0].set_ylabel(\"Training Loss\")\n",
        "axs[0].set_title(\"Training Loss vs Epochs\")\n",
        "axs[0].legend()\n",
        "\n",
        "for learning_rate, loss in val_loss_results.items():\n",
        "    axs[1].plot(loss, label=f\"lr={learning_rate}\")\n",
        "axs[1].set_xlabel(\"Epochs\")\n",
        "axs[1].set_ylabel(\"Validation Loss\")\n",
        "axs[1].set_title(\"Validation Loss vs Epochs\")\n",
        "axs[1].legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90Zg_auJz13x"
      },
      "source": [
        "### Note down anything you have observed from your experiment (one or two sentences will suffice). Write 2-3 sentences in `responses.tex`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5c-_kWZ543I"
      },
      "source": [
        "# Part 4: Add Pooling and Subsampling (5 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCCHip8t8EJR"
      },
      "source": [
        "Modify your ConvNet implementation by adding max pooling with stride = 2 and kernel = 2 after each convolutional block's ReLU. You might want to use [MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html).\n",
        "\n",
        "Hint: since adding max pooling layers will change the dimensions of the convolution layers' outputs, you will need to modify the input dimesnionality of the first fully-connected layer as well.\n",
        "\n",
        "**NOTE:** You will need to have a separate max-pool layer each time you max-pool so that the autograder can check your network. (This is just an architecture choice. Having one max-pool layer and using it multiple times also works. You should try to think about why that is the case.) Name the layers ``pool1``, ``pool2``, and ``pool3``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTOK-i2F7zRD"
      },
      "outputs": [],
      "source": [
        "#----------------------------------------------------#\n",
        "# TODO: Implement ConvNetMaxPooling in submission.py #\n",
        "#----------------------------------------------------#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWWY-trBJr2S"
      },
      "source": [
        "Use the following test as a sanity check. This test does not guarantee correctness of the entire implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12BphDog6C7Z"
      },
      "outputs": [],
      "source": [
        "def testConvNetMaxPool():\n",
        "  net = submission.ConvNetMaxPooling()\n",
        "  input_tensor = torch.randn(1, 3, 64, 64)\n",
        "  output = net(input_tensor)\n",
        "  assert(output.size() ==torch.Size([1, 4]))\n",
        "\n",
        "testConvNetMaxPool()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO7J0wPQDZrs"
      },
      "source": [
        "# Part 5: Implement BatchNorm (17.5 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS_0mpLSN0x5"
      },
      "source": [
        "Here we will implement a custom BatchNorm layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8HTu0wRD64v"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------#\n",
        "# TODO: Implement BatchNormalization in submission.py #\n",
        "#-----------------------------------------------------#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRYRDpZnJulT"
      },
      "source": [
        "\n",
        "\n",
        "Use the following test as a sanity check. This test does not guarantee correctness of the entire implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMptItectF7K"
      },
      "outputs": [],
      "source": [
        "def testBatchNorm():\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Initialize batchnorm layers\n",
        "    student_bn = submission.BatchNormalization(num_features=3)\n",
        "    student_bn.train()\n",
        "    torch_bn = nn.BatchNorm2d(num_features=3)\n",
        "    torch_bn.train()\n",
        "\n",
        "    for i in range(50):\n",
        "        # Generate random input data\n",
        "        input_data = np.random.randn(10, 3, 28, 28)\n",
        "        input_tensor = torch.tensor(input_data, dtype=torch.float32)\n",
        "\n",
        "        # Forward pass through both layers\n",
        "        student_output = student_bn.forward(input_tensor)\n",
        "        torch_output = torch_bn(input_tensor)\n",
        "\n",
        "        # Convert outputs to numpy arrays for comparison\n",
        "        student_output_np = student_output.detach().numpy()\n",
        "        torch_output_np = torch_output.detach().numpy()\n",
        "\n",
        "        # Check if outputs are close within a tolerance\n",
        "        assert np.allclose(student_output_np, torch_output_np, atol=1e-3)\n",
        "\n",
        "    # Generate random input data\n",
        "    input_data = np.random.randn(10, 3, 28, 28)\n",
        "    input_tensor = torch.tensor(input_data, dtype=torch.float32)\n",
        "\n",
        "    # Switch to inference mode\n",
        "    student_bn.eval()\n",
        "    torch_bn.eval()\n",
        "\n",
        "    # Forward pass through both layers\n",
        "    student_output = student_bn.forward(input_tensor)\n",
        "    torch_output = torch_bn(input_tensor)\n",
        "\n",
        "    # Convert outputs to numpy arrays for comparison\n",
        "    student_output_np = student_output.detach().numpy()\n",
        "    torch_output_np = torch_output.detach().numpy()\n",
        "\n",
        "    # Check if outputs are close within a tolerance\n",
        "    print(np.max(student_output_np-torch_output_np))\n",
        "    assert np.allclose(student_output_np, torch_output_np, atol=1e-3)\n",
        "\n",
        "    print(\"BatchNormalization test passed!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    testBatchNorm()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nYqPMHZFyLL"
      },
      "source": [
        "Now modify the ConvNetMaxPooling model by adding BatchNormalization layers after each convolutional layer. Name the layers ``bn1``, ``bn2``, and ``bn3``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ojs_APG9FHf1"
      },
      "outputs": [],
      "source": [
        "#----------------------------------------------------------------------------#\n",
        "# TODO: Implemment ConvNetBN to have BatchNorm layers after each convolution #\n",
        "#----------------------------------------------------------------------------#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1uE872QnGPu"
      },
      "source": [
        "# Part 6: Dropout (12.5 pts)\n",
        "Task: Custom Dropout\n",
        "\n",
        "Now, you will implement your own custom dropout layer from scratch and compare its performance with PyTorch's built-in dropout layer. Refer back to the lecture notes to remind yourself on what dropout is and how it is a regularization technique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dohHH2s9nE_C"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------#\n",
        "# TODO: Implement CustomDropout in submission.py #\n",
        "#------------------------------------------------#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQAkkXDPiiA5"
      },
      "source": [
        "Use the following as a sanity check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGmCIOeYifQX"
      },
      "outputs": [],
      "source": [
        "# Toy example\n",
        "class LinearDropout(nn.Module):\n",
        "    def __init__(self, num_features, dropout=0.1):\n",
        "        super(LinearDropout, self).__init__()\n",
        "        self.linear = nn.Linear(num_features, 1)\n",
        "        # init to all ones\n",
        "        self.linear.weight.data.fill_(1)\n",
        "        self.dropout = submission.CustomDropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(self.dropout(x))\n",
        "\n",
        "def testDropout():\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Initialize batchnorm layers\n",
        "    linear_dropout = LinearDropout(512)\n",
        "\n",
        "    input_tensor = torch.ones((1, 512), dtype=torch.float32)\n",
        "    # Expand the input tensor 1000 times\n",
        "    input_tensor = input_tensor.expand(1000, -1)\n",
        "    linear_dropout.eval()\n",
        "    output = linear_dropout(input_tensor)\n",
        "    print(f'Test mode output mean: {output.mean()}')\n",
        "    print(f'Test mode output std: {output.std()}')\n",
        "    # Check if outputs are close within a tolerance\n",
        "    deterministic_output = output[0]\n",
        "    assert torch.allclose(output.mean(), deterministic_output, atol=1e-5)\n",
        "    assert torch.allclose(output.std(), torch.zeros(1), atol=1e-5)\n",
        "\n",
        "\n",
        "    linear_dropout.train()\n",
        "    output_list = []\n",
        "    for i in range(50):\n",
        "        # accumulate predictions\n",
        "        output = linear_dropout(input_tensor)\n",
        "        output_list.append(output)\n",
        "\n",
        "    output_list = torch.cat(output_list)\n",
        "    output_mean = output_list.mean()\n",
        "    print(f'Train mode output mean: {output_mean}')\n",
        "    print(f'Train mode output std: {output_list.std()}')\n",
        "    # Check if outputs are close within a tolerance\n",
        "    assert torch.allclose(output_mean, deterministic_output, atol=1e-1)\n",
        "    # StDev should be large\n",
        "    assert output_list.std() > 1\n",
        "\n",
        "    print(\"Dropout test passed!\")\n",
        "\n",
        "testDropout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TInWy8ypatFK"
      },
      "source": [
        "Create ConvNetDropout by copying your ConvNetBN model and modifying it by adding a dropout layer with probability 0.5 after each ReLU.\n",
        "\n",
        "**NOTE:** You will need to have a separate dropout layer for each of the layers, so that it can pass the autograder. (Like before, this is just an architecture choice. Having one dropout layer and using it multiple times also works and you should convince yourself of this too.) Name these layers ``drop1``, ``drop2``, ``drop3``, and ``drop4``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_Rhvd6MbuZ6"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------------------#\n",
        "# TODO: Implement ConvNetDropout in submission.py #\n",
        "#-------------------------------------------------#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMSLapw46PgP"
      },
      "source": [
        "# Part 7: Create a ResNet (45 pts)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZxlvdFPFUuE"
      },
      "source": [
        "## 7.1: Residual Blocks (35 pts)\n",
        "\n",
        "We first begin by implementing a residual block. Recall from homework 1 that the difference between a residual block and plain convolutional layers is the identity mapping, which adds the input to the output function.\n",
        "\n",
        "You will implement a residual block with the following structure:\n",
        "1.   Two convolutional layers with 3x3 kernels/filters, a stride of `stride`, and padding = 1:\n",
        "\n",
        "  a. The first convolutional layer takes an input with `in_channel` number of channels and returns an output with `interm_channel` number of channels. Name this layer `conv1`.\n",
        "\n",
        "  b. The second convolutional layer takes an input with `interm_channel` number of channels and returns an output with `out_channel` number of channels. Name this layer `conv2`.\n",
        "\n",
        "2.   Two batch normalization layers, applied after each convolutional layer. Name these layers `bn1` and `bn2`. **Use Pytorch's implementation of BatchNorm.**\n",
        "3. A ReLU activation function, applied after the first batch norm.\n",
        "4. Add a 1x1 convolutional layer (name it ``conv3``) to the residual branch. This layer adjusts the input tensor so that its number of channels matches the number produced by the main branch (``out_channel``). Use a kernel size of 1x1 and the same stride (``stride``) as the main convolutions to guarantee that both the spatial dimensions and channel count align for the subsequent addition.\n",
        "5. After the elementwise summation of the residual branch (the input tensor adjusted by conv3) and the main branch (output from conv2 after normalization), apply a final ReLU activation function to the resulting tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31gJq3-dFZFJ"
      },
      "source": [
        "Here are some Pytorch docs that may be useful:\n",
        "\n",
        "\n",
        "*   Conv2d: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "*   BatchNorm2d: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html\n",
        "* ReLU: https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-n40gz8FdmH"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------#\n",
        "# TODO: Implement ResidualBlock in submission.py #\n",
        "#------------------------------------------------#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z3pKmBKr4ZK"
      },
      "source": [
        "Use the following test as a sense check. It is very basic and does not guarantee correctness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hco3lXREr3eS"
      },
      "outputs": [],
      "source": [
        "def test_residual_block():\n",
        "  in_channel = 9\n",
        "  interm_channel = 6\n",
        "  out_channel = 3\n",
        "  blk = submission.ResidualBlock(in_channel, interm_channel, out_channel)\n",
        "  X = torch.randn(4, in_channel, 6, 6)\n",
        "\n",
        "  conv1_out = blk.conv1(X)\n",
        "  conv2_out = blk.conv2(conv1_out)\n",
        "\n",
        "  assert conv1_out.shape == torch.Size([4, interm_channel, 6, 6])\n",
        "  assert conv2_out.shape == torch.Size([4, out_channel, 6, 6])\n",
        "  assert blk(X).shape == torch.Size([4, out_channel, 6, 6])\n",
        "  print(\"Tests passed\")\n",
        "\n",
        "test_residual_block()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvl5OuzgFspp"
      },
      "source": [
        "## 7.2: ResNet Model (10 pts)\n",
        "\n",
        "We can now move on to implementing an entire Residual Network. The main portion of a ResNet, as you will implement, simply involves stacking Residual Blocks together. The entire architecture is as follows:\n",
        "\n",
        "1. The first step is to apply a 7x7 convolution, followed by a batch normalization layer (with activation) and Max Pooling. This step is initialized in `self.first`.\n",
        "\n",
        "2. Depending on the depth of the network, stack residual blocks together in what is referred to as a \"block layer\" in this assignment (a more detailed description below, but essentially a stack of blocks with the same number of output channels). This is the part of the ResNet you will be implementing.\n",
        "\n",
        "3. The output of the residual blocks is average pooled, flattened, then passed into a linear classifier. This step is initialized in `self.last`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZo1r7nnFu7R"
      },
      "source": [
        "Finish the implementation for a ResNet below, in the following sequence:\n",
        "1. Implement the function `block_layer`. In this assignment, a `block_layer` just refers to a stack of `num_blocks` blocks that has number of input channels `in_channel` to the first block, and `out_channel` as the number of output channels for all blocks.\n",
        "\n",
        "  In other words, for simplicity sake (and, as it turns out, what is common in actual ResNets such as the ResNet18), each Residual Block will have the same number of output channels for each convolutional layer (so in this assignment, going back to the ResidualBlock class above, `interm_channel` ==`out_channel`). Use the ResidualBlock class above when implementing the functon `block_layer`.\n",
        "\n",
        "2. Add 2 block layers to the initialization of the ResNet, each layer with `num_blocks` blocks stacked together.\n",
        "\n",
        "  a. Block layer 1 would have an input with `layer1_channel` number of channels. Call this layer `layer1`.\n",
        "\n",
        "  b. Block layer 2 would have an input with `layer2_channel` number of channels and output with `out_channel` number of channels. Call this layer `layer2`.\n",
        "\n",
        "3. Implement the forward function based on the architecture described above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omoLx3XSFzHv"
      },
      "source": [
        "Here are some Pytorch docs for functions referenced in the provided implementation below:\n",
        "\n",
        "\n",
        "\n",
        "*   Sequential: https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html\n",
        "*   LazyConv2d: https://pytorch.org/docs/stable/generated/torch.nn.LazyConv2d.html\n",
        "* LazyBatchNorm2d: https://pytorch.org/docs/stable/generated/torch.nn.LazyBatchNorm2d.html\n",
        "* MaxPool2d: https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n",
        "* AdaptiveAvgPool2d: https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html\n",
        "* LazyLinear: https://pytorch.org/docs/stable/generated/torch.nn.LazyLinear.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yOdC5fyF1oi"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------#\n",
        "# TODO: Implement ResNet in submission.py #\n",
        "#-----------------------------------------#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l07xVYKZJ0yt"
      },
      "source": [
        "Use the following test as a sense check. It is very basic and does not guarantee correctness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tx1lGk5sWqx"
      },
      "outputs": [],
      "source": [
        "def test_resnet():\n",
        "  layer1_channel = 64\n",
        "  layer2_channel = 128\n",
        "  out_channel = 256\n",
        "  num_blocks = 2\n",
        "  net = submission.ResNet(num_blocks, layer1_channel, layer2_channel, out_channel)\n",
        "  X = torch.randn(1, 1, 96, 96)\n",
        "\n",
        "  layer1_out = net.layer1(net.first(X))\n",
        "  layer2_out = net.layer2(layer1_out)\n",
        "  net(X)\n",
        "  assert layer1_out.shape[1] == layer2_channel\n",
        "  assert layer2_out.shape[1] == out_channel\n",
        "  assert net(X).shape == torch.Size([1, 4])\n",
        "  print(\"Tests passed\")\n",
        "\n",
        "test_resnet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk7aPvIDpggd"
      },
      "source": [
        "# Part 8: Comparing the Models (5 pts)\n",
        "\n",
        "The following cells train the five models you have implemented.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-K-rFYWkhyNi"
      },
      "outputs": [],
      "source": [
        "#train ConvNet\n",
        "model_conv = submission.ConvNet()\n",
        "model_conv = model_conv.to(device)\n",
        "optimizer = optim.SGD(model_conv.parameters(), lr=0.001, momentum=0.9)\n",
        "data_loader = train_dataloader\n",
        "epochs = 40\n",
        "convnet_train_loss, convnet_val_loss = submission.train(model_conv, data_loader, val_dataloader, criterion, optimizer, epochs, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_E9Zy6W_Jx2"
      },
      "outputs": [],
      "source": [
        "#train ConvNetMaxPooling\n",
        "model_pool = submission.ConvNetMaxPooling()\n",
        "model_pool = model_pool.to(device)\n",
        "optimizer = optim.SGD(model_pool.parameters(), lr=0.001, momentum=0.9)\n",
        "data_loader = train_dataloader\n",
        "epochs = 40\n",
        "convnet_max_pooling_train_loss, convnet_max_pooling_val_loss = submission.train(model_pool, data_loader, val_dataloader, criterion, optimizer, epochs, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SP69R_DiTnD"
      },
      "outputs": [],
      "source": [
        "#train ConvNetBN\n",
        "model_BN = submission.ConvNetBN()\n",
        "model_BN.to(device)\n",
        "optimizer = optim.SGD(model_BN.parameters(), lr=0.001, momentum=0.9)\n",
        "data_loader = train_dataloader\n",
        "epochs = 40\n",
        "convnet_bn_train_loss, convnet_bn_val_loss = submission.train(model_BN, data_loader, val_dataloader, criterion, optimizer, epochs, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdNIsR0eiTrk"
      },
      "outputs": [],
      "source": [
        "#train ConvNetDropout\n",
        "model_dropout = submission.ConvNetDropout()\n",
        "model_dropout.to(device)\n",
        "optimizer = optim.SGD(model_dropout.parameters(), lr=0.001, momentum=0.9)\n",
        "data_loader = train_dataloader\n",
        "epochs = 40\n",
        "convnet_dropout_train_loss, convnet_dropout_val_loss = submission.train(model_dropout, data_loader, val_dataloader, criterion, optimizer, epochs, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnyiuOIZh5QE"
      },
      "outputs": [],
      "source": [
        "#train resnet\n",
        "layer1_channel = 12\n",
        "layer2_channel = 64\n",
        "out_channel = 128\n",
        "num_blocks = 2\n",
        "model_res = submission.ResNet(num_blocks, layer1_channel, layer2_channel, out_channel)\n",
        "model_res.to(device)\n",
        "optimizer = optim.SGD(model_res.parameters(), lr=0.001, momentum=0.9)\n",
        "data_loader = train_dataloader\n",
        "epochs = 40\n",
        "resnet_train_loss, resnet_val_loss = submission.train(model_res, data_loader, val_dataloader, criterion, optimizer, epochs, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "logFwyOAhfHI"
      },
      "source": [
        "Now run the cell below to compare the training losses at each epoch for each of the three models above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyGkYR2cyvTt"
      },
      "outputs": [],
      "source": [
        "x = [epoch for epoch in range(epochs)]\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.plot(x,convnet_train_loss, color='red',label='ConvNet')\n",
        "ax1.plot(x,convnet_max_pooling_train_loss, color='green',label='ConvNetMaxPooling')\n",
        "ax1.plot(x,convnet_bn_train_loss, color='yellow',label='ConvNetBN')\n",
        "ax1.plot(x,convnet_dropout_train_loss, color='orange',label='ConvNetDropout')\n",
        "ax1.plot(x,resnet_train_loss, color='blue', label='ResNet')\n",
        "\n",
        "ax1.set_title(\"Training Loss\")\n",
        "ax1.set_xlabel(\"Epochs\")\n",
        "ax1.set_ylabel(\"Loss\")\n",
        "\n",
        "ax2.plot(x,convnet_val_loss, color='red',label='ConvNet')\n",
        "ax2.plot(x,convnet_max_pooling_val_loss, color='green',label='ConvNetMaxPooling')\n",
        "ax2.plot(x,convnet_dropout_val_loss, color='orange',label='ConvNetDropout')\n",
        "ax2.plot(x,convnet_bn_val_loss, color='yellow',label='ConvNetBN')\n",
        "\n",
        "ax2.plot(x,resnet_val_loss, color='blue', label='ResNet')\n",
        "\n",
        "ax2.set_title(\"Validation Loss\")\n",
        "ax2.set_xlabel(\"Epochs\")\n",
        "ax2.set_ylabel(\"Loss\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot_Az6Pkbagc"
      },
      "source": [
        "### Q: What do you notice about the graphs above and the differences between the five models you have implemented? Write 2-3 sentences in ``responses.tex``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJ0h0ikOHHkP"
      },
      "outputs": [],
      "source": [
        "model_res.eval()\n",
        "# -------------------------------\n",
        "# Generate predictions on the test set\n",
        "# -------------------------------\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        data = data.to(device)\n",
        "        output = model_res(data)\n",
        "        preds = output.argmax(dim=1)\n",
        "        predictions.extend(preds.cpu().numpy().tolist())\n",
        "\n",
        "# -------------------------------\n",
        "# Save the predictions to a CSV file\n",
        "# -------------------------------\n",
        "pred_df = pd.DataFrame(predictions, columns=[\"preds\"])\n",
        "file_save_path = os.path.join(base_dir, \"resnet_preds.csv\")\n",
        "pred_df.to_csv(file_save_path, index=False)\n",
        "\n",
        "print(\"Predictions saved to 'resnet_preds.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYg_eGu4Ltyz"
      },
      "source": [
        "# Once finished, upload `submission.py` and `resnet_preds.csv` to  [***Coding Assignment 1***](https://www.gradescope.com/courses/963234/assignments/5744368); do not change the filenames. Upload a PDF of your written responses to [***Coding Assignment 1 Written Responses***](https://www.gradescope.com/courses/963234/assignments/5744437)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cs4782",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
