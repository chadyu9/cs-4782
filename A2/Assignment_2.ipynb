{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLtmVTkTxffd"
      },
      "source": [
        "## <h1><center>Assignment 2: Sentiment Analysis</center></h1>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<center><img src=\"https://www.cs.cornell.edu/courses/cs4782/2025sp/images/clapperboard_attention.jpeg\"></center>\n",
        "\n",
        "\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**GOAL:** In this project you will be implementing a variety of different NLP models to analyze whether IMBD movie reviews are positive or negative (sentiment analysis). You will also gain familiarity with the HuggingFace platform, which is commonly used to share machine learning models, datasets, and more.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "**WHAT YOU'LL SUBMIT:** Your submission to Gradescope includes:\n",
        "\n",
        "\n",
        "1.   A `.zip` file uploaded to ***[Coding Assignment 2](https://www.gradescope.com/courses/963234/assignments/5850403)***  containing the following files:\n",
        "\n",
        "<center>\n",
        "\n",
        "\\#|Files\n",
        "---|---\n",
        "i. | `submission.py`\n",
        "ii. |`LR_google.csv`\n",
        "iii. |`LR_student.csv`\n",
        "iv. |`Transformer_preds.csv`\n",
        "v. |`LSTM_preds.csv`\n",
        "\n",
        "</center>\n",
        "\n",
        "\n",
        "2.   A `.txt`file with responses to questions in the notebook uploaded to ***[Coding Assignment 2 Responses](https://www.gradescope.com/courses/963234/assignments/5850976)***\n",
        "\n",
        "*More on how you are expected to access, modify and save these files as you follow along the instructions in the notebook.*\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "**DO's:**\n",
        "\n",
        "\n",
        "1.   **Recommendation:** Finish coding and debugging on CPU; only use the GPU in the end to get the final results.\n",
        "2.   **Running on GPU:** You can click on the runtime option and change your runtime type to the **T4 GPU (this should make your training faster)**\n",
        "3.   As before, all functionality you need to modify is within `submission.py`.\n",
        "4.   Remember to execute all code cells sequentially, not just those you’ve edited, to ensure your code runs properly.\n",
        "5.   Please cite any external sources you use to complete this assignment in your written responses.\n",
        "6.   Before starting your work, please review <a href=\"https://s3.amazonaws.com/ecornell/global/eCornellPlagiarismPolicy.pdf\">eCornell's policy regarding plagiarism</a> (the presentation of someone else's work as your own without source credit).\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "**DONT's:**\n",
        "\n",
        "\n",
        "1.   DO NOT change the names of any provided functions, classes, or variables within the existing code cells, as this will interfere with grading.\n",
        "2.   DO NOT delete any provided code/imports.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "***NOTE:***\n",
        "    \n",
        "*You can resubmit your work as many times as necessary before the submission deadline. If you experience difficulty or have questions about this exercise, use the Ed discussion board to engage with your peers or seek assistance from the TAs.*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuzCW1xBp5--"
      },
      "source": [
        "# Part 0: Setting up the Colab environment.\n",
        "\n",
        "The new few code blocks will set up your Colab environment.  Upload the `a2_release` folder to your Google Drive and run/update the cells below, following the TODO instructions. Just like in the first assignment, you must specify the paths to your implementation so it can be accessed by this notebook (see *TODO 1*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "38lgpvAjE3wD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting filelock (from datasets)\n",
            "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-19.0.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pandas (from datasets)\n",
            "  Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (89 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
            "Collecting tqdm>=4.66.3 (from datasets)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.11.13-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
            "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from datasets) (24.2)\n",
            "Collecting pyyaml>=5.1 (from datasets)\n",
            "  Downloading PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
            "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
            "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
            "  Downloading propcache-0.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (10 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.18.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets)\n",
            "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
            "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.11.13-cp312-cp312-macosx_11_0_arm64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.4/456.4 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.0/468.0 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-19.0.1-cp312-cp312-macosx_12_0_arm64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.3/173.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl (11.4 MB)\n",
            "Downloading xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
            "Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
            "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozenlist-1.5.0-cp312-cp312-macosx_11_0_arm64.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.1.0-cp312-cp312-macosx_11_0_arm64.whl (29 kB)\n",
            "Downloading propcache-0.3.0-cp312-cp312-macosx_11_0_arm64.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "Downloading yarl-1.18.3-cp312-cp312-macosx_11_0_arm64.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytz, xxhash, tzdata, tqdm, pyyaml, pyarrow, propcache, multidict, fsspec, frozenlist, filelock, dill, attrs, aiohappyeyeballs, yarl, pandas, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohappyeyeballs-2.4.6 aiohttp-3.11.13 aiosignal-1.3.2 attrs-25.1.0 datasets-3.3.2 dill-0.3.8 filelock-3.17.0 frozenlist-1.5.0 fsspec-2024.12.0 huggingface-hub-0.29.1 multidict-6.1.0 multiprocess-0.70.16 pandas-2.2.3 propcache-0.3.0 pyarrow-19.0.1 pytz-2025.1 pyyaml-6.0.2 tqdm-4.67.1 tzdata-2025.1 xxhash-3.5.0 yarl-1.18.3\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Collecting stop_words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: stop_words\n",
            "  Building wheel for stop_words (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for stop_words: filename=stop_words-2018.7.23-py3-none-any.whl size=32940 sha256=11941865af99407cf93ffa58d10f57c797dbad5992bc32b1265afd762a222ed8\n",
            "  Stored in directory: /Users/ryannoonan/Library/Caches/pip/wheels/98/8d/87/5894deb0270ab49fc65555daa606a7d1dfa144f456bb9e0795\n",
            "Successfully built stop_words\n",
            "Installing collected packages: stop_words\n",
            "Successfully installed stop_words-2018.7.23\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from transformers) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from transformers) (2.2.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Downloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/ryannoonan/.pyenv/versions/3.12.2/envs/ryan-global/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.8/284.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.4/418.4 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: safetensors, regex, tokenizers, transformers\n",
            "Successfully installed regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.0 transformers-4.49.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install stop_words\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "V_kgeMmlFpT_"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m     27\u001b[39m random.seed(\u001b[32m0\u001b[39m)\n\u001b[32m     28\u001b[39m torch.manual_seed(\u001b[32m0\u001b[39m)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import datasets\n",
        "\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import sys\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "from typing import List\n",
        "import textwrap\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04aaIJ_A7cfa"
      },
      "outputs": [],
      "source": [
        "# TODO 0: Mount your Google Drive; this allows the runtime environment to access your drive.\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xouOZJpNqAyz"
      },
      "outputs": [],
      "source": [
        "# NOTE: Make sure your path does NOT include a '/' at the end!\n",
        "base_dir = \"/content/gdrive/MyDrive/<path-to-a2-release>\"\n",
        "sys.path.append(base_dir)\n",
        "## END TODO\n",
        "\n",
        "# This makes sure the submission module is reloaded whenever you make edits.\n",
        "%load_ext autoreload\n",
        "%aimport submission\n",
        "%autoreload 1\n",
        "import submission\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(F\"Device set to {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdARAa2VN0-z"
      },
      "source": [
        "# Part 1: Create a Dataset\n",
        "The dataset https://huggingface.co/datasets/imdb that we will be using consists of movie reviews from the IMDB website that are labelled as either `\"Negative\" (0)` or `\"Positive\" (1)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWKFNTX1N0RX"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "imdb = load_dataset(\"imdb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdZYvR4FO1UT"
      },
      "source": [
        "This next set of code will create the train and test splits used for the assignment. To speed up training time, we will only be using a subset of the full imdb dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrxgKP3IO0c1"
      },
      "outputs": [],
      "source": [
        "train_dataset = imdb[\"train\"].shuffle(seed=82).select([i for i in list(range(3000))])\n",
        "val_dataset = imdb[\"test\"].shuffle(seed=82).select([i + 301 for i in list(range(300))])\n",
        "test_dataset = imdb[\"test\"].shuffle(seed=82).select([i for i in list(range(300))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSjmMNC4hQeb"
      },
      "outputs": [],
      "source": [
        "train_df = train_dataset.to_pandas()\n",
        "val_df = val_dataset.to_pandas()\n",
        "test_df = test_dataset.to_pandas()\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHOehgtkPW1r"
      },
      "source": [
        "Visualize training examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oc2K6wJLRq5Q"
      },
      "outputs": [],
      "source": [
        "print('Negative Review', '\\n')\n",
        "print(textwrap.fill(train_dataset[2]['text'], 130), '\\n')\n",
        "\n",
        "print('Positive Review Review', '\\n')\n",
        "print(textwrap.fill(train_dataset[10]['text'], 130))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1FRbMOCTq4R"
      },
      "source": [
        "# Part 2: Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH5iNk-EfQoR"
      },
      "source": [
        "Before we start, let's learn some word embeddings for the words found in our movie review dataset. <br>\n",
        "Run the following cells to:\n",
        "\n",
        "*   process our dataset,\n",
        "*   train a word2vec embedding model on the words in our dataset,\n",
        "*   visualize these embeddings in 2D space.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJjYvU-rfQ28"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import stop_words\n",
        "\n",
        "from gensim.models import word2vec\n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMKrZ20mz6Qc"
      },
      "source": [
        "The following code cells will clean the text in the imdb review dataset. This includes removing characters that are not alpha-numeric and removing stop words (common words in the English language that do not convey much meaning, e.g. the, and, it, etc.). This is a common processing step in many NLP pipelines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp1vEOPefQ9w"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "STOP_WORDS = nltk.corpus.stopwords.words()\n",
        "\n",
        "def clean_sentence(val):\n",
        "    '''\n",
        "    This function remove chars that are not letters or numbers. It then removes\n",
        "    stop words (common words in the English language that do not convey much\n",
        "    meaning, e.g. the, and, it, etc.).\n",
        "    '''\n",
        "    val = val.lower()\n",
        "    val = val.replace('<br />', '')\n",
        "    val = val.replace('.', '. ')\n",
        "    val = val.replace('!', '! ')\n",
        "    regex = re.compile('([^\\s\\w]|_)+')\n",
        "    sentence = regex.sub('', val).lower()\n",
        "    sentence = sentence.split(\" \")\n",
        "\n",
        "    for word in list(sentence):\n",
        "        if word in STOP_WORDS:\n",
        "            sentence.remove(word)\n",
        "\n",
        "    sentence = \" \".join(sentence)\n",
        "    return sentence\n",
        "\n",
        "def clean_dataframe(data):\n",
        "    data = data.dropna(how=\"any\")\n",
        "\n",
        "    for col in ['text']:\n",
        "        data[col] = data[col].apply(clean_sentence)\n",
        "\n",
        "    return data\n",
        "\n",
        "data = clean_dataframe(train_df)\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d_OOEuohzTL"
      },
      "outputs": [],
      "source": [
        "def build_corpus(data):\n",
        "    '''\n",
        "    Creates a list of lists containing words from each sentence.\n",
        "    '''\n",
        "    corpus = []\n",
        "    for col in ['text']:\n",
        "        for sentence in data[col].items():\n",
        "            word_list = sentence[1].split(\" \")\n",
        "            corpus.append([word for word in word_list if len(word) != 0])\n",
        "\n",
        "    return corpus\n",
        "\n",
        "corpus = build_corpus(data)\n",
        "corpus[0:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUK5k05qQE1Z"
      },
      "source": [
        "The following cell trains a word2vec model on our cleaned dataset of movie reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUsjCSJphzZ-"
      },
      "outputs": [],
      "source": [
        "w2v_model = word2vec.Word2Vec(corpus, vector_size=100, window=20, min_count=320, workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNXUMqNi0kjH"
      },
      "source": [
        "We can visualize our word embeddings in 2D space using a TSNE plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgoZOj9Fhzc-"
      },
      "outputs": [],
      "source": [
        "def tsne_plot(model):\n",
        "    '''\n",
        "    Creates an TSNE model and plots it. This will help visualize the distances\n",
        "    between word embeddings in 2D space.\n",
        "    '''\n",
        "    labels = []\n",
        "    tokens = []\n",
        "\n",
        "    for word in model.wv.key_to_index:\n",
        "        tokens.append(model.wv[word])\n",
        "        labels.append(word)\n",
        "\n",
        "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
        "    new_values = tsne_model.fit_transform(np.asarray(tokens))\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "    for value in new_values:\n",
        "        x.append(value[0])\n",
        "        y.append(value[1])\n",
        "\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    for i in range(len(x)):\n",
        "        color = sns.color_palette('Set2')[2]\n",
        "        plt.scatter(x[i], y[i], color = color)\n",
        "        plt.annotate(labels[i], xy=(x[i], y[i]), xytext=(5, 2), textcoords='offset points', ha='right',va='bottom')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__qFbeMIiIBU"
      },
      "outputs": [],
      "source": [
        "tsne_plot(w2v_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vCg6nnTvjdD"
      },
      "source": [
        "## Part 2.1: Logistic Regression with Word Embeddings\n",
        "\n",
        "Now that we have a Word2Vec model that can generate embeddings for the words in our reviews, we can use these embeddings to train a Logistic Regression model to classify the sentiment of these reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eRxhQQyXzJ2"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waLYfQrpZ8uW"
      },
      "source": [
        "In order to generate our inputs to the Logistic Regression model, start by implementing the `get_word_embeddings` function, which given a single review (i.e. a sequence of words), returns the list of corresponding word embeddings for each of the words in the review.\n",
        "\n",
        "[This](https://radimrehurek.com/gensim/models/word2vec.html#usage-examples) Word2vec documentation may be helpful in implementing `get_word_embeddings`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXvPokK3vxdz"
      },
      "outputs": [],
      "source": [
        "# TODO 1: Implement get_word_embeddings in submission.py\n",
        "from submission import get_word_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkuvX71IXY1y"
      },
      "source": [
        "Next, implement `get_reviews_embeddings`, which given a dataframe containing a list of reviews, returns the list of word embeddings for each review in the input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-1PDBAPXKoB"
      },
      "outputs": [],
      "source": [
        "# TODO 2: Implement get_reviews_embeddings in submission.py\n",
        "from submission import get_reviews_embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmw22F2ubAHl"
      },
      "source": [
        "Finally, we will use this function to obtain the word embeddings for the train, test, and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cC0sklXiX5sQ"
      },
      "outputs": [],
      "source": [
        "word_embeddings_train = get_reviews_embeddings(w2v_model, data)\n",
        "word_embeddings_val = get_reviews_embeddings(w2v_model, clean_dataframe(val_df))\n",
        "word_embeddings_test = get_reviews_embeddings(w2v_model, clean_dataframe(test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QDydy2DWfbY"
      },
      "source": [
        "Before we can train a logistic regression model on these reviews, we need to ensure that all of our inputs into the model have the same dimensions. Since reviews can have different lengths (i.e. have different word counts), we need a method to standardize the size of the embeddings for each review in a way that does not depend on the length of the review.\n",
        "\n",
        "A simple way to do this is to perfom max pooling of the word embeddings in each review to obtain a single vector of length `d`, where `d` is the size of the word embeddings.\n",
        "\n",
        "Implement the function `max_pool`, which performs this pooling operation.\n",
        "\n",
        "Some reviews may not have any words in our vocabulary. If that is the case, we should return a vector of zeros for the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veEnccfHvxhQ"
      },
      "outputs": [],
      "source": [
        "# TODO 3: Implement max_pool in submission.py\n",
        "from submission import max_pool\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1zKGzLWdI3Z"
      },
      "outputs": [],
      "source": [
        "X_train_max_pool = [\n",
        "    max_pool(review, w2v_model.vector_size) for review in word_embeddings_train\n",
        "]\n",
        "X_val_max_pool = [\n",
        "    max_pool(review, w2v_model.vector_size) for review in word_embeddings_val\n",
        "]\n",
        "X_test_max_pool = [\n",
        "    max_pool(review, w2v_model.vector_size) for review in word_embeddings_test\n",
        "]\n",
        "\n",
        "y_train = train_df['label']\n",
        "y_val = val_df['label']\n",
        "y_test = test_df['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hpBbfjvdKbe"
      },
      "source": [
        "Now that we have our training data set up, we can train our model.\n",
        "\n",
        "We will use the sklearn library's LogisticRegression model class the create and train a logistic regression classification model `logreg_model` as a baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8JcEghIdYgz"
      },
      "outputs": [],
      "source": [
        "logreg_model = LogisticRegression(max_iter=1000).fit(X_train_max_pool, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjQ1jn8Dds4Z"
      },
      "source": [
        "The following code will display the accuracy of your model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrmkNN5kZNOE"
      },
      "outputs": [],
      "source": [
        "y_test_pred = logreg_model.predict(X_test_max_pool)\n",
        "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Test Accuracy: {accuracy_test:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfHzVZaKeZw0"
      },
      "source": [
        "Now let's see how your model stacks up against a logistic regression model using Google's pre-trained word embeddings. We will load in pretrained embeddings below. This cell may take several minutes to run (*~12 minutes*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea2FsnUEvxkD"
      },
      "outputs": [],
      "source": [
        "google_w2v_model = api.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2udGKCm1ex4I"
      },
      "source": [
        "Just as we did before, we can use Google's word2vec model to obtain work embeddings for each of the reviews in our dataset and max pool them. However, Google's word2vec doesn't store it's vocabulary in attribute `wv`. <br> Update your `get_word_embeddings` function, to check for different `types` of models input to the function. <br> The expected behavior and i/o of the function still remains the same only adjusted to accommodate multiple models types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pM1gnoWhjOAA"
      },
      "outputs": [],
      "source": [
        "# TODO 4: Add support for Google's word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaQyY6L8YGS9"
      },
      "outputs": [],
      "source": [
        "google_embeddings_train = get_reviews_embeddings(google_w2v_model, data)\n",
        "google_embeddings_val = get_reviews_embeddings(google_w2v_model, clean_dataframe(val_df))\n",
        "google_embeddings_test = get_reviews_embeddings(google_w2v_model, clean_dataframe(test_df))\n",
        "\n",
        "X_train_max_pool_google = [\n",
        "    max_pool(review, google_w2v_model.vector_size) for review in google_embeddings_train\n",
        "]\n",
        "X_val_max_pool_google = [\n",
        "    max_pool(review, google_w2v_model.vector_size) for review in google_embeddings_val\n",
        "]\n",
        "X_test_max_pool_google = [\n",
        "    max_pool(review, google_w2v_model.vector_size) for review in google_embeddings_test\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZm8cfBm1Shc"
      },
      "source": [
        "Just like before, we use the sklearn library's LogisticRegression model class. This time, we use the word embeddings from google to compare what accuracy we achieve with slightly more sophisticated embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTtL4CdYh--0"
      },
      "outputs": [],
      "source": [
        "logreg_model_google = LogisticRegression(max_iter=1000).fit(X_train_max_pool_google, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRBlwJjzhEvM"
      },
      "outputs": [],
      "source": [
        "y_test_pred_google = logreg_model_google.predict(X_test_max_pool_google)\n",
        "accuracy_google = accuracy_score(y_test, y_test_pred_google)\n",
        "print(f\"Test Accuracy (Google's Word2Vec): {accuracy_google:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIXUUcnsCn1Q"
      },
      "source": [
        "# Part 3: LSTMs for Text Classification (20 pts)\n",
        "\n",
        "## 3.1: LSTM Model (10 pts)\n",
        "\n",
        "We first begin by implementing the LSTM model that we will later train for sentiment analysis. The entire architecture is as follows:\n",
        "1.  **LSTM** takes the data, an initial hidden state, and an initial cell state. (`batch_first` should be set to `True`)\n",
        "2. **Dense Layer**:\n",
        "  - **relu** **ReLU** nonlinearity on the hidden. Use nn.ReLU().\n",
        "  - **fc1** fully-connected layer with `hidden_size*num_layers` input dimensions and `128` output features\n",
        "  -  **relu** **ReLU** nonlinearity on the hidden state. The same relu layer can be used across the entire forward pass.\n",
        "  - **fc2** Passing the hidden state through another fully connected layer with `128` input dimensions and `num_classes` output features\n",
        "\n",
        "Instead of implementing the LSTM architecture from scratch, you may make use of [PyTorch's built-in LSTM class](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html).\n",
        "\n",
        "Note: During the forward pass, you will need to get the final hidden state from the LSTM to pass into the MLP. You should look at the LSTM documentation to figure out what the shape of the hidden unit is and reshape it so the input to the MLP is `batch_size x (num_layers x hidden_size)`.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMlBaizWCkuc"
      },
      "outputs": [],
      "source": [
        "#TODO 5: Implement LSTM in submission.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHgmDPi3ZnMl"
      },
      "source": [
        "## 3.2: LSTM Training (10 pts)\n",
        "\n",
        "We can now move on to training our LSTM on our training data. <br>First you will need to use the downloaded Google word2vec embeddings to create embeddings for input to your LSTM. You will do this by implementing a function `reviews_processing` that processes the reviews embedded with Google's word2vec model. <br>\n",
        "\n",
        "\n",
        "*   We will clip the sequences to length 40.\n",
        "*   If a review has fewer than 40 word embeddings, you should pad the review with 0 vectors so that the final sequence has 40 embeddings.\n",
        "\n",
        "Once we have preprocessed the reviews to have the same length, we can then create a `CustomLSTMDataset` to store the reviews. Finally, we can  create a data loader will give us batched data for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTS3NgYWV04l"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "class CustomLSTMDataset(Dataset):\n",
        "  def __init__(self, embeddings, labels):\n",
        "    self.embeddings = embeddings\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.embeddings)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.embeddings[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeLPSQHTxHGi"
      },
      "outputs": [],
      "source": [
        "# TODO 6: Implement reviews_processing in submission.py\n",
        "from submission import reviews_processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSb6RJJZ-A2k"
      },
      "outputs": [],
      "source": [
        "length = 40\n",
        "batch_size = 16\n",
        "\n",
        "train_data = CustomLSTMDataset(reviews_processing(google_embeddings_train, length), y_train)\n",
        "validation_data = CustomLSTMDataset(reviews_processing(google_embeddings_val, length), y_val)\n",
        "test_data = CustomLSTMDataset(reviews_processing(google_embeddings_test, length), y_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1liU__uVIjxb"
      },
      "source": [
        "Now create a training loop to train the model, where the data_loader provides batches of (inputs, labels). We will keep track of the train and validation losses and the validation accuracy at each epoch, which should be outputted by the `train` function. As a reminder, for each batch the training loop should:\n",
        "\n",
        "1. Zero out the gradients of the model\n",
        "2. Perform a forward pass through the model.\n",
        "3. Compute the loss using the specified criterion.\n",
        "4. Perform a backward pass and update the model parameters using the optimizer.\n",
        "5. Step the optimzer.\n",
        "\n",
        "Additionally, calculate the validation loss and accuracy at the end of each epoch using the `val` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "my5SSQaboafa"
      },
      "outputs": [],
      "source": [
        "# TODO 7: Implement val and train in submission.py\n",
        "from submission import val, train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hT4RkCUYnax"
      },
      "outputs": [],
      "source": [
        "from submission import LSTM\n",
        "\n",
        "num_layers = 2\n",
        "input_size = 300\n",
        "hidden_size = 64\n",
        "seq_length = 40\n",
        "num_classes = 2\n",
        "\n",
        "# you may change the learning rate and numbers of epochs run\n",
        "learning_rate = 0.01\n",
        "lstm_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Initialize LSTM model\n",
        "lstm_model = LSTM(num_layers, input_size, hidden_size, seq_length, num_classes).to(device)\n",
        "\n",
        "#Initialize optimizer\n",
        "optimizer = optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
        "\n",
        "#run training\n",
        "lstm_train_loss, lstm_val_loss, lstm_val_acc = train(lstm_model, train_loader, val_loader, criterion, lstm_epochs, optimizer, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odUDojJIoLZz"
      },
      "source": [
        "Now run the cell below to compare the training losses, validation losses, and validation accuracy of the LSTM model over each training epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j55KNu5-oLZ0"
      },
      "outputs": [],
      "source": [
        "x = [epoch + 1 for epoch in range(lstm_epochs)]\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 4))\n",
        "\n",
        "ax1.plot(x, lstm_train_loss, color='green', label='Train Loss')\n",
        "ax1.plot(x, lstm_val_loss, color='red', label='Validation Loss')\n",
        "ax1.set_title(\"Training & Validation Loss\")\n",
        "ax1.set_xlabel(\"Epochs\")\n",
        "ax1.set_ylabel(\"Loss\")\n",
        "\n",
        "\n",
        "ax2.plot(x, lstm_val_acc, color='blue', label='Validation Accuracy')\n",
        "ax2.set_title(\"Validation Accuracy\")\n",
        "ax2.set_xlabel(\"Epochs\")\n",
        "ax2.set_ylabel(\"Accuracy\")\n",
        "\n",
        "ax1.legend()\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cI9x9c_7dEwg"
      },
      "outputs": [],
      "source": [
        "_, lstm_accuracy = val(lstm_model, test_loader, criterion, device)\n",
        "\n",
        "print(f\"Test Accuracy (LSTM): {lstm_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4MjLRn6bEdV"
      },
      "source": [
        "# Part 4: Transformers (50 pts)\n",
        "\n",
        "The next NLP model we will be applying to our sentiment analysis task is the Transformer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdF7-pcygI7Z"
      },
      "source": [
        "###Positional Encoding\n",
        "The following code implements the positional encoding that will be used to inject information on the position of each element in the input sequence into the model. The positional encoding is added to the input embeddings before they are passed through the rest of the encoder, as shown in the figure below\n",
        "\n",
        "<center>Image of the positional embedding section of a transformer</center>\n",
        "\n",
        "<center><img src=\"https://www.cs.cornell.edu/courses/cs4782/2025sp/images/positional_encoding.png\"></center>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Crv2Uun0hN5B"
      },
      "outputs": [],
      "source": [
        "# TODO 8: Look at PositionalEncoding in submission.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUy0lSmtCsUn"
      },
      "source": [
        "### Q1: Based on the provided implementation of PositionalEncoding, what is the formula used to assign an embedding to each position/index `i` in the input sequence? What is one benefit of using this function/formula specifically to generate position embeddings?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D2vPBijDTcE"
      },
      "source": [
        "**Answer: add your answer to responses.tex**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzAvlCqgVOqM"
      },
      "source": [
        "## 4.1: Attention Mechanism (15 pts)\n",
        "First, let's revisit how the multi-head attention layer works.\n",
        "\n",
        "**A)** Recall that given query, key, and value matrices $Q \\in \\mathbb{R}^{n \\times d_q}$, $K \\in \\mathbb{R}^{n \\times d_k}$, and $V \\in \\mathbb{R}^{n \\times d_v}$, where $d_q = d_k$ and $n$ is the sequence length, the attention equation for a single head is:\n",
        "$$\\texttt{attention}(Q, K, V) = \\texttt{softmax} \\left( \\frac{QK^T}{\\sqrt{d_k}} \\right)V$$\n",
        "\n",
        "**B)** To produce the query, key, and value matrices from the model inputs, weight matrices $W^q$, $W^k$, and $W^v$ are used to transform the input sequence X into the Q, K, and V matrices.\n",
        "\n",
        "$$Q = X(W^q)^T$$\n",
        "$$K = X(W^k)^T$$\n",
        "$$V = X(W^v)^T$$\n",
        "\n",
        "**C)** If we have $h$ attention heads, the output from each attention head can be represented as:\n",
        "$$\\texttt{head}_i = \\texttt{attention}(Q_i, K_i, V_i)\\space\\space\\space \\forall \\space i \\in [0, h]$$\n",
        "\n",
        "$$\\texttt{head}_i = \\texttt{attention}(X(W^q_i)^T, X(W^k_i)^T, X(W^v_i)^T)\\space\\space\\space \\forall \\space i \\in [0, h]$$\n",
        "\n",
        "**Note**: to make the dimensions work out, given $h$ attention heads, $d_k = \\frac{d_{model}}{h}$, where $d_{model}$ is the dimension of the embeddings.\n",
        "\n",
        "**D)** The multi-headed attention output is the concatenation of the output of each head as follows:\n",
        "\n",
        "$$\\texttt{multi-head} = [\\texttt{head}_1, \\texttt{head}_2, ...\\texttt{head}_h]$$\n",
        "\n",
        "**E)** Finally,  a weight matrix $W^o$ is used to transform the multi-head output and generate the final output of the multi-head attention layer, i.e.\n",
        "\n",
        "$$\\texttt{MultiHead}(Q, K, V) = [\\texttt{head}_1, \\texttt{head}_2, ...\\texttt{head}_h](W^o)^T$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2Hz9BpRhOat"
      },
      "outputs": [],
      "source": [
        "# TODO 9: Implement MultiHeadAttention in submission.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpgV-McVVSXD"
      },
      "source": [
        "### Now, complete the TODOs in the following order\n",
        "\n",
        "1. **TODO 9.1**: Initialize the linear layers $W^q$, $W^k$, and $W^v$ and $W^o$ used to generate the Q, K, V matrices and transform the multi-head output.\n",
        "\n",
        "2. Understand the logic used to split the heads.(*barbaric! I know!*)\n",
        "\n",
        "3. **TODO 9.2** Implement the `compute_attention` function that performs operation in **step (A)** in the description above\n",
        "\n",
        "4. Understand the logic used to combine the heads.\n",
        "\n",
        "5. **TODO 9.3** Implement the forward pass that performs the entire attention process described previouly and returns the output as per operation in **step (E)** above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQtwld86abHK"
      },
      "source": [
        "### Q3: Describe the matrix size transformations as they happen from steps 1-5. Specificaly, what is the shape of:\n",
        "### i.  the input to the `split_heads` function?\n",
        "### ii. the output from the `split_heads` function?\n",
        "### iii.`multi-head` variable in the description above?\n",
        "### iv. final output of `Multi-Head(Q, K, V)`?\n",
        "\n",
        "### Answers expected as matrix shapes in terms of $n$, $d_{model}$, $d_q$, $d_k$, $d_v$ and $h$. You can use the additional variable $b$ to represent batch size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp7xzJtBanJP"
      },
      "source": [
        "**Answer: add your answer to responses.tex**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isZm3ADXi2eL"
      },
      "source": [
        "## 4.2: Position-Wise Feed-Forward Neural Network (5 pts)\n",
        "Next, we will implement the position-wise feed-forward portion of the encoder. The feed-forward architecture is as follows:\n",
        "- **fc1**: fully-connected layer with `d_model` input dimensions and `d_ff` output features\n",
        "- **ReLU** nonlinearity\n",
        "- **fc2**: fully-connected layer with `d_ff` input dimensions and `d_model` output features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPstc5lni7Jk"
      },
      "outputs": [],
      "source": [
        "# TODO 10: Implement FeedForward in submission.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdaATuW4gI-U"
      },
      "source": [
        "## 4.3: Encoder Layer (15 pts)\n",
        "\n",
        "Next, we will implement a single encoder layer (shown in the dashed red outline).\n",
        "\n",
        "<center>Image of encoder section of transformer</center>\n",
        "\n",
        "<center><img src=\"https://www.cs.cornell.edu/courses/cs4782/2025sp/images/encoder.png\"></center>\n",
        "\n",
        "You will implement an encoder layer with the following structure:\n",
        "\n",
        "1. A single multi-head attention layer with `num_heads` heads. This attention layer performs self-attention, i.e. the key, query, and value matrices are all generated from the same input. Name this layer `self_attn`.\n",
        "\n",
        "2. A single layer normalization layer with input shape `d_model`. Name this layer `norm1`. As shown in the diagram, the inputs to this layer are the following:\n",
        "\n",
        "  a. Input embeddings which were input to the multi-head attention block.\n",
        "\n",
        "  b. Output of the multi-head attention block. A Dropout (with dropout probaility `p`) should be applied to the multi-head attention output before adding.\n",
        "\n",
        "3. A feed-forward block with input dimension `d_model` and hidden layer dimension `d_ff`. Name this layer `feed_forward`.\n",
        "\n",
        "4. A second layer normalization layer with input shape `d_model`. Name this layer `norm2`. Similar to the first layer norm layer, this layer also has two inputs:\n",
        "\n",
        "  a. The input to the feed-forward network.\n",
        "\n",
        "  b. Output of the feed-forward network. Dropout (with dropout probaility `p`) should be applied to the feed-forward output before adding.\n",
        "\n",
        "5. A Dropout layer named `dropout` to be used in the layer norms `norm1` and `norm2`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI6ZKRgNhPYb"
      },
      "outputs": [],
      "source": [
        "# TODO 11: Implement EncoderLayer in submission.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7w05yZ3Pvfd"
      },
      "source": [
        "## Part 4.4: (Encoder-only)  Transformer (15 pts)\n",
        "\n",
        "Now that we created all of its components, we can implement the full Transformer Encoder. Similar to the ResNet you implemented in the previous assignment, the main portion of the Encoder involves stacking Encoder Layers together. The entire architecture is as follows:\n",
        "\n",
        "1. The first step is to add the positional encodings into the input embeddings, using the `PositionalEncoding` module we provided. Name this layer `positional_encoding`. Dropout (with dropout probaility `p`) should be applied to the final output embedding from this layer.\n",
        "\n",
        "2. Initialize a Dropout layer named `dropout` to be used as per step 1.\n",
        "\n",
        "3. Next, the output from step 1 is passed through `num_layers` encoder layers. These encoder layers are store in a `ModuleList` variable named `encoder_layers`.\n",
        "\n",
        "4. The output of the encoder layers (`batch_size x max_seq_length x d_model`) is then mean-pooled across the sequence to yield an output of shape `batch_size x d_model`.\n",
        "\n",
        "5. Finally, the pooled output is passed through two fully-connected layers, with a `ReLU` non-linearity applied before each fully-connected layer. The first fully-connected layer `fc1` should have `128` output features and the second fully-connected layer `fc2` should have `num_classes` output features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwP8qUnchQ1v"
      },
      "outputs": [],
      "source": [
        "# TODO 12: Implement Transformer in submission.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZykoooNSg1Hd"
      },
      "source": [
        "## Transformer Training\n",
        "\n",
        "The following cells will train the transformer model. They make use of the same same datasets and functions that you created in part 3 for the LSTM. (*~12 minutes on CPU*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cw_YhS53hbiC"
      },
      "outputs": [],
      "source": [
        "from submission import Transformer\n",
        "\n",
        "d_model = 300\n",
        "num_heads = 4\n",
        "num_layers = 4\n",
        "d_ff = 1024\n",
        "max_seq_length = 40\n",
        "dropout = 0.1\n",
        "num_classes = 2\n",
        "\n",
        "transformer_epochs = 10 # you may change the number of epochs (note: 10 epochs should take ~15 minutes to train on Colab CPU-only)\n",
        "lr = 0.0001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "transformer = Transformer(num_classes, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout).to(device)\n",
        "optimizer = optim.Adam(transformer.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5SvUiMgmkXR"
      },
      "outputs": [],
      "source": [
        "transformer_train_loss, transformer_val_loss, transformer_val_acc = train(transformer, train_loader, val_loader, criterion, transformer_epochs, optimizer, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjdW9tNKmgV1"
      },
      "source": [
        "Now run the cell below to compare the training losses, validation losses, and validation accuracy of the transformer model over each training epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQeOEEKPhRjo"
      },
      "outputs": [],
      "source": [
        "x = [epoch + 1 for epoch in range(transformer_epochs)]\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 4))\n",
        "\n",
        "ax1.plot(x, transformer_train_loss, color='green', label='Train Loss')\n",
        "ax1.plot(x, transformer_val_loss, color='red', label='Validation Loss')\n",
        "ax1.set_title(\"Transformer Training & Validation Loss\")\n",
        "ax1.set_xlabel(\"Epochs\")\n",
        "ax1.set_ylabel(\"Loss\")\n",
        "\n",
        "ax2.plot(x, transformer_val_acc, color='blue', label='Validation Accuracy')\n",
        "ax2.set_title(\"Transformer Validation Accuracy\")\n",
        "ax2.set_xlabel(\"Epochs\")\n",
        "ax2.set_ylabel(\"Accuracy\")\n",
        "\n",
        "ax1.legend()\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apRsONPBhRpa"
      },
      "outputs": [],
      "source": [
        "_, transformer_accuracy = val(transformer, test_loader, criterion, device)\n",
        "\n",
        "print(f'Transformer Test Accuracy: {transformer_accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1ntQYqRbPqN"
      },
      "source": [
        "#Part 5: Pre-trained Models (10 pts)\n",
        "\n",
        "As discussed in lecture, in natural language processing, it is common to make use of pre-trained models that can be fine-tuned to a specific task to improve performance.\n",
        "\n",
        "Through the Hugging Face platform, we have access to a wide variety of these pre-trained models. For this portion of the assignment, we will be using the DistilBERT model, a small, fast, cheap, and light Transformer model trained by distilling BERT base. We will be fine-tuning DistilBERT for our sentiment analysis task.\n",
        "\n",
        "For this portion of the assignment you will need to connect to GPU runtime.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZmuPDeUjvFm"
      },
      "source": [
        "First, run the following code to download the pre-trained DistilBERT model and its tokenizer from Hugging Face.\n",
        "\n",
        "Notice that after we download the DistilBERT model, we call `.to(device)`. This sends the model to the GPU. Later in the assignment, when inputting data into the model, you will similarly need to ensure that the data is also on the GPU, i.e. in the same location as the model.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LJXWIQubVxC"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "import torch.optim as opt\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "bert_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k27pB4oBktrR"
      },
      "source": [
        "The following code implements a custom dataset class which will be used in the data loader for the DistilBERT model you will be fine-tuning.\n",
        "\n",
        "The `__getitem__` function is automatically called by the dataloader called when iterating over the dataset, e. g. during training, to produce the input that will eventually be passed into the model. This implementation of `__getitem__` uses the DistilBERT tokenizer to produce the following values:\n",
        "\n",
        "\n",
        "*   `'source_ids'`: The list of token ids representing the input sequence.\n",
        "*   `'source_mask'`: The list of indices specifying which tokens should be attended to by the model. Since different sequences in the same batch might have different lengths, in order to put them all in the same tensor, the sequences must be padded or truncated to the same length. The source attention mask tells the model which elements in `source_ids` are padding so that the model does not attend to them. A more detailed explanation can be found [here](https://huggingface.co/transformers/v3.5.1/glossary.html#attention-mask).\n",
        "\n",
        "Finally, the output of `__getitem__` also includes the example's ground truth label (`'label'`).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdmleLeybV28"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data\n",
        "\n",
        "class CustomClassDataset(data.Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        super(CustomClassDataset, self).__init__()\n",
        "\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.out = self.data['label']\n",
        "        self.text = self.data['text']\n",
        "        self.max_len = 256\n",
        "\n",
        "    def __len__(self):\n",
        "        '''\n",
        "        Returns the length of the dataset.\n",
        "        '''\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Returns the training/validation/test example as index idx.\n",
        "        '''\n",
        "\n",
        "        text = str(self.text[idx])\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        source = self.tokenizer([text], padding='max_length', truncation = True, return_tensors=\"pt\", max_length = self.max_len)\n",
        "        source_ids = source['input_ids'].squeeze()\n",
        "        source_mask = source['attention_mask'].squeeze()\n",
        "\n",
        "        label = self.out[idx]\n",
        "\n",
        "        inputs = {\n",
        "            'source_ids': source_ids.to(dtype=torch.long),\n",
        "            'source_mask': source_mask.to(dtype=torch.long),\n",
        "            'label': label\n",
        "        }\n",
        "\n",
        "        return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZA8DhHmbV6N"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_data = CustomClassDataset(train_df, tokenizer)\n",
        "train_loader = DataLoader(train_data, batch_size, True, pin_memory=True, drop_last=True)\n",
        "\n",
        "val_data = CustomClassDataset(val_df, tokenizer)\n",
        "val_loader = DataLoader(val_data, batch_size, True, pin_memory=True, drop_last=False)\n",
        "\n",
        "test_data = CustomClassDataset(test_df, tokenizer)\n",
        "test_loader = DataLoader(test_data, batch_size, True, pin_memory=True, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUS0l7MGlpxf"
      },
      "source": [
        "## 5.1: Fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ_0tt0oyvI5"
      },
      "source": [
        "To de-duplicate the code necessary for processing each batch of inputs during training and validation, implement the function `process_batch`, which will input the examples in a batch into the model, and return the model outputs, predicted labels, and loss for that batch. During validation, the function will also output the total number of examples in the batch and the number of examples for which the model predicted the correct label. These numbers will later be used to calculate model accuracy.\n",
        "\n",
        "[This link](https://huggingface.co/docs/transformers/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification) provides more information on the inputs to a forward pass through the DistilBERT model. For the purposes of this assignment, you will only need to provide the `input_ids` and `attention_mask` as inputs.\n",
        "\n",
        "\n",
        "\n",
        "Here are some Pytorch docs that may be useful in processing the model outputs:\n",
        "\n",
        "*   argmax: https://pytorch.org/docs/stable/generated/torch.argmax.html\n",
        "*   sum: https://pytorch.org/docs/stable/generated/torch.sum.html\n",
        "*   eq: https://pytorch.org/docs/stable/generated/torch.eq.html\n",
        "*   size: https://pytorch.org/docs/stable/generated/torch.Tensor.size.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kz5XrQKvyuqx"
      },
      "outputs": [],
      "source": [
        "# TODO 13: Implement process_batch in submission.py\n",
        "from submission import process_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7t-vM7kyvx4"
      },
      "source": [
        "We provide the validation and training function for fine-tuning the DistilBERT model, which will make use of the `process_batch` function that you implemented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dx_1kMQrbV9U"
      },
      "outputs": [],
      "source": [
        "def val_bert(model, val_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    model (torch.nn.Module): The deep learning model to be trained.\n",
        "    val_data_loader (torch.utils.data.DataLoader): DataLoader for the validation dataset.\n",
        "    criterion (torch.nn.Module): Loss function to compute the training loss.\n",
        "\n",
        "    Outputs:\n",
        "    Tuple of (validation loss, validation accuracy)\n",
        "    \"\"\"\n",
        "    val_running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader, 0):\n",
        "\n",
        "            _, batch_metrics = process_batch(bert_model, data, criterion,device,  val=True)\n",
        "\n",
        "            val_running_loss += batch_metrics['loss'].cpu().item()\n",
        "            correct += batch_metrics['num_correct']\n",
        "            total += batch_metrics['batch_size']\n",
        "\n",
        "    return val_running_loss, (correct / total).item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEPFTcpWbWA7"
      },
      "outputs": [],
      "source": [
        "def train_bert(model, train_loader, criterion, epochs, optim, lr_scheduler, device):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    model (torch.nn.Module): The deep learning model to be trained.\n",
        "    val_data_loader (torch.utils.data.DataLoader): DataLoader for the validation dataset.\n",
        "    criterion (torch.nn.Module): Loss function to compute the training loss.\n",
        "    epochs: Number of epochs to train.\n",
        "    optim: The optimizer for training.\n",
        "    lr_scheduler: Learning rate scheduler for training.\n",
        "\n",
        "    Outputs:\n",
        "    Tuple of (train_loss_arr, val_loss_arr, val_acc_arr), an array of the training and validation\n",
        "    losses and validation accuracy at each epoch\n",
        "    \"\"\"\n",
        "    train_loss_arr = []\n",
        "    val_loss_arr = []\n",
        "    val_acc_arr = []\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch_idx, data in enumerate(train_loader):\n",
        "\n",
        "            _, metrics = process_batch(bert_model, data, criterion, device)\n",
        "\n",
        "            loss = metrics['loss'].cpu().item()\n",
        "\n",
        "            optim.zero_grad()\n",
        "            metrics['loss'].backward()\n",
        "            optim.step()\n",
        "\n",
        "            running_loss += loss\n",
        "\n",
        "        val_running_loss, val_acc = val_bert(model, val_loader, criterion, device)\n",
        "        train_loss_arr.append(running_loss)\n",
        "        val_loss_arr.append(val_running_loss)\n",
        "        val_acc_arr.append(val_acc)\n",
        "\n",
        "        print(\"epoch:\", epoch+1, \"training loss:\", round(running_loss, 3), 'validation loss:', round(val_running_loss, 3), 'validation accuracy:', round(val_acc*100, 2))\n",
        "\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    return train_loss_arr, val_loss_arr, val_acc_arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_iJgP5PA_Ql"
      },
      "source": [
        "The following cells will fine-tune the DistilBERT model.\n",
        "\n",
        "Note: if you would like to re-start fine-tuning the DistilBERT model (i.e. after changing hyperparameters), you will need to re-download the pre-trained DistilBERT weights by running the first cell in part 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qKfezrIxbgP"
      },
      "outputs": [],
      "source": [
        "scheduler_step_size = 15\n",
        "\n",
        "# you may change the learning rate and training epochs\n",
        "learning_rate = 3e-5\n",
        "bert_epochs = 5\n",
        "\n",
        "optim = opt.Adam(bert_model.parameters(), learning_rate)\n",
        "lr_scheduler = opt.lr_scheduler.StepLR(optim, scheduler_step_size, 0.1)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZyxNyHFhLL0"
      },
      "outputs": [],
      "source": [
        "bert_train_loss, bert_val_loss, bert_val_acc = train_bert(bert_model, train_loader, criterion, bert_epochs, optim, lr_scheduler, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Sp2GT7_Awje"
      },
      "source": [
        "Now run the cell below to compare the training losses, validation losses, and validation accuracy of the DistilBERT model over each training epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONO0wsmKlvcT"
      },
      "outputs": [],
      "source": [
        "x = [epoch + 1 for epoch in range(bert_epochs)]\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 4))\n",
        "\n",
        "ax1.plot(x, bert_train_loss, color='green', label='Train Loss')\n",
        "ax1.plot(x, bert_val_loss, color='red', label='Validation Loss')\n",
        "ax1.set_title(\"BERT Training & Validation Loss\")\n",
        "ax1.set_xlabel(\"Epochs\")\n",
        "ax1.set_ylabel(\"Loss\")\n",
        "\n",
        "ax2.plot(x, bert_val_acc, color='blue', label='Validation Accuracy')\n",
        "ax2.set_title(\"BERT Validation Accuracy\")\n",
        "ax2.set_xlabel(\"Epochs\")\n",
        "ax2.set_ylabel(\"Accuracy\")\n",
        "\n",
        "ax1.legend()\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voz2XyBnlvcU"
      },
      "outputs": [],
      "source": [
        "_, bert_accuracy = val_bert(bert_model, test_loader, criterion, device)\n",
        "\n",
        "print('Fine-tuned DistilBERT Test Set Accuracy:', round(bert_accuracy, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_r5vE77dsFZ"
      },
      "source": [
        "# Part 6: Model Comparisons\n",
        "\n",
        "Finally, now that we have implemented a variety of different NLP models to perform sentiment analysis, we can compare their performance on the IMDB dataset.\n",
        "\n",
        "The following code will generate a barplot comparing the test accuracies of each of the five models you trained throughout this assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKT_3i8odw22"
      },
      "outputs": [],
      "source": [
        "model_names = ['LR', 'LR + W2V', 'LSTM', 'transformer', 'distilBERT']\n",
        "\n",
        "accuracies = [accuracy_test, accuracy_google, lstm_accuracy, transformer_accuracy, bert_accuracy]\n",
        "y_pos = np.arange(len(accuracies))\n",
        "\n",
        "color = sns.color_palette('Set2')[2]\n",
        "plt.bar(y_pos, height = accuracies, color = color)\n",
        "\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(y_pos, model_names)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot_Az6Pkbagc"
      },
      "source": [
        "### Q3: What do you notice about the graph above and the differences between the five models you have implemented? Are the results consistent with what you expected? How do pre-trained models compare to models you trained from scratch? Write 3-4 sentences below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMby2UqkcX8d"
      },
      "source": [
        "**Answer: add your answer to responses.tex**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IisbOtP0pcoc"
      },
      "source": [
        "## Run the following to create your submission files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikPtVEnnpcoc"
      },
      "outputs": [],
      "source": [
        "length = 40\n",
        "batch_size = 16\n",
        "\n",
        "test_data = CustomLSTMDataset(\n",
        "    reviews_processing(google_embeddings_test, length), y_test\n",
        ")\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "# store predictions for LSTM and Transformer models\n",
        "def get_predictions(model, data_loader):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    preds = []\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(data_loader):\n",
        "        inputs = inputs.to(device, dtype=torch.float32)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "\n",
        "        preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
        "\n",
        "    p = pd.DataFrame(preds, columns=[\"preds\"])\n",
        "    file_save_path = os.path.join(base_dir, f\"{model.__class__.__name__}_preds.csv\")\n",
        "    p.to_csv(file_save_path, index=False)\n",
        "\n",
        "\n",
        "# Store predictions for LSTM and Transformer models\n",
        "get_predictions(lstm_model, test_loader)\n",
        "get_predictions(transformer, test_loader)\n",
        "\n",
        "# Store predictions for Logistic Regression\n",
        "logreg_model = LogisticRegression(max_iter=1000)\n",
        "logreg_model.fit(X_train_max_pool, y_train)\n",
        "y_test_pred = logreg_model.predict(X_test_max_pool)\n",
        "preds = pd.DataFrame(y_test_pred, columns=[\"preds\"])\n",
        "file_save_path = os.path.join(base_dir, \"LR_student.csv\")\n",
        "preds.to_csv(file_save_path, index=False)\n",
        "\n",
        "logreg_model_google = LogisticRegression(max_iter=1000)\n",
        "logreg_model_google.fit(X_train_max_pool_google, y_train)\n",
        "y_test_pred_google = logreg_model_google.predict(X_test_max_pool_google)\n",
        "preds = pd.DataFrame(y_test_pred_google, columns=[\"preds\"])\n",
        "file_save_path = os.path.join(base_dir, \"LR_google.csv\")\n",
        "preds.to_csv(file_save_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wdJSvGGqU-j"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cs4782",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
